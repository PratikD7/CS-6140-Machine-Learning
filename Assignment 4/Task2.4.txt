1) DIABETES Dataset

The accuracy, precision and recall values are slightly on the higher side when the model is regularized.

a) Performance of Logistic Regression: (lambda=0)
		Training Accuracies          Testing Accuracies         Training Precisions         Testing Precisions  		Training Recalls 		Testing Recalls	
		0.78508771929824561			 0.69736842105263153		0.73936170212765961			0.63157894736842102			0.5864978902953587      0.42857142857142855
		0.78216374269005851			 0.76315789473684215		0.72674418604651159			0.8125						0.5506607929515418		0.68421052631578949
		0.78216374269005851		     0.72368421052631582		0.72674418604651159			0.66666666666666663 		0.57383966244725737		0.5
		0.78654970760233922			 0.73684210526315785		0.7407407407407407			0.75						0.59071729957805907		0.42857142857142855
		0.77631578947368418			 0.81578947368421051		0.72916666666666663			0.77777777777777779			0.58091286307053946		0.58333333333333337
		0.7792397660818714			 0.73684210526315785		0.73513513513513518			0.64000000000000001			0.5714285714285714		0.59259259259259256
		0.77777777777777779			 0.80263157894736847		0.73118279569892475			0.80000000000000004			0.5714285714285714		0.59259259259259256
		0.76900584795321636			 0.86842105263157898		0.72680412371134018			0.76470588235294112			0.57317073170731703		0.68421052631578949
		0.783625730994152			 0.72368421052631582		0.7409326424870466			0.5714285714285714			0.59336099585062241		0.5
		0.77485380116959068			 0.78947368421052633		0.72820512820512817			0.66666666666666663			0.58436213991769548		0.54545454545454541
	
Mean:	0.779678362573				 0.765789473684				0.73374035556				0.708132451226				0.577637951868			0.553953697375

b) Performance of Regularized Logistic Regression: (Optimal value of lambda = 2.33)

		Training Accuracies         Testing Accuracies          Training Precisions         Testing Precisions  		Training Recalls 		Testing Recalls	
		0.783625730994152			0.7894736842105263          0.7473118279569892        	0.7083333333333334			0.5791666666666667      0.6538461538461539          
		0.7865497076023392			0.6973684210526315			0.7383720930232558			0.7777777777777778			0.5570175438596491		0.5526315789473685
		0.783625730994152			0.7763157894736842			0.7458563535911602			0.7307692307692307			0.569620253164557		0.6551724137931034
		0.7719298245614035			0.8289473684210527			0.732620320855615			0.8125						0.5637860082304527		0.5652173913043478
		0.7777777777777778			0.7763157894736842			0.7382198952879581			0.625						0.5802469135802469		0.6521739130434783
		0.7807017543859649			0.8026315789473685			0.7446808510638298			0.7142857142857143			0.5785123966942148		0.625
		0.7792397660818714			0.8157894736842105			0.743455497382199			0.7222222222222222			0.5819672131147541		0.5909090909090909
		0.7850877192982456			0.8026315789473685			0.7379679144385026			0.8571428571428571			0.5847457627118644		0.6
		0.7865497076023392			0.75						0.7486631016042781			0.6666666666666666			0.5857740585774058		0.5925925925925926
		0.7850877192982456			0.7631578947368421			0.7411167512690355			0.8							0.6033057851239669  	0.3333333333333333
		
Mean:	0.7820175438596492			0.7802631578947369			0.7418264606472823			0.7414697802197803			0.5784142601723778		0.5820876467769469
---------------------------------------------------------------------------------------------------------------------------------------------------------------------

2) BREASTCANCER Dataset

The accuracy, precision and recall values are slightly on the higher side when the model is regularized.

a) Performance of Logistic Regression: (lambda=0)

		Training Accuracies         Testing Accuracies          Training Precisions         Testing Precisions  		Training Recalls 		Testing Recalls	
		0.98412698412698407			0.9821428571428571			0.9831460674157303			0.96666666666666667			0.97222222222222221		1.0       
		0.98611111111111116			1.0							0.989247311827957			1.0							0.97354497354497349		1.0
		0.98809523809523814			0.9821428571428571			0.99459459459459465			0.95238095238095233			0.97354497354497349		1.0
		0.99206349206349209			0.9464285714285714			1.0							0.96153846153846156			0.97802197802197799		0.92592592592592593
		0.98809523809523814			1.0							0.99465240641711228			1.0							0.97382198952879584		1.0
		0.99007936507936511			0.9642857142857143			0.99465240641711228			1.0							0.97894736842105268		0.89473684210526316
		0.99404761904761907			0.9285714285714286			0.99447513812154698			0.95999999999999996			0.98901098901098905		0.88888888888888884
		0.98809523809523814			0.9821428571428571			0.9946236559139785			0.94999999999999996			0.97368421052631582		1.0
		0.98611111111111116			1.0							0.98952879581151831			1.0							0.97422680412371132		1.0
		0.98809523809523814]		0.9821428571428571			0.99473684210526314			1.0							0.97422680412371132		0.93333333333333335

Mean:	0.988492063492				0.976785714286				0.992965721862				0.979058608059				0.976125231307			0.964288499025
		
b) Performance of Regularized Logistic Regression: (Optimal value of lambda = 1.0)

		Training Accuracies         Testing Accuracies          Training Precisions         Testing Precisions  		Training Recalls 		Testing Recalls	
		0.98611111111111116			1.0							0.98888888888888893        	1.0 						0.97267759562841527		[1.0
		0.98809523809523814			0.9821428571428571			0.98913043478260865			1.0							0.978494623655914		0.95238095238095233
		0.98809523809523814			0.9821428571428571			0.99450549450549453			0.95454545454545459			0.9731182795698925		1.0
		0.98611111111111116			1.0							0.98901098901098905			1.0							0.97297297297297303		1.0
		0.98809523809523814			0.9821428571428571			0.98913043478260865			1.0							0.978494623655914		0.95238095238095233
		0.98809523809523814			0.9821428571428571			0.99465240641711228			1.0							0.97382198952879584		0.9375
		0.99206349206349209			0.9642857142857143			0.99447513812154698			1.0							0.98360655737704916		0.91666666666666663
		0.98412698412698407			1.0							0.98404255319148937			1.0							0.9732620320855615		1.0
		0.98809523809523814			1.0							0.99453551912568305			1.0							0.978494623655914		1.0
		0.99007936507936511			0.9642857142857143			0.99453551912568305			0.95238095238095233			0.978494623655914		0.95238095238095233
		
Mean: 	0.987896825397				0.985714285714				0.991290737795				0.990692640693				0.975862750866			0.971130952381

---------------------------------------------------------------------------------------------------------------------------------------------------------------------
3) SPAMBASE Dataset

The accuracy, precision and recall values are slightly on the higher side when the model is regularized.

a) Performance of Logistic Regression: (lambda=0)

		Training Accuracies         Testing Accuracies          Training Precisions         Testing Precisions  		Training Recalls 		Testing Recalls	
		0.92898550724637685			0.91086956521739126  		0.92834293026231607       	0.89655172413793105			0.88854868340477644     0.87150837988826813       
		0.92729468599033815			0.92391304347826086			0.9282511210762332			0.92121212121212126			0.88461538461538458		0.87356321839080464
		0.93043478260869561			0.89782608695652177			0.92721518987341767			0.9096774193548387			0.89438339438339443		0.81034482758620685
		0.92898550724637685			0.91956521739130437			0.92898272552783112			0.9320987654320988			0.88807339449541289		0.85310734463276838
		0.92657004830917877			0.93478260869565222			0.92632927610506088			0.94011976047904189			0.88440366972477069		0.88700564971751417
		0.92705314009661832			0.92173913043478262			0.92801556420233466			0.91847826086956519			0.88224414303329224		0.88947368421052631
		0.92584541062801928			0.93043478260869561			0.92991563919532771			0.92045454545454541			0.87806372549019607		0.90000000000000002
		0.92463768115942024			0.91521739130434787			0.92602206359506811			0.8936170212765957			0.87815384615384617		0.89839572192513373
		0.91038647342995171			0.92826086956521736			0.91489361702127658			0.92553191489361697			0.8499073502161828		0.9015544041450777
		0.92294685990338166			0.92826086956521736			0.92213642213642211			0.9157303370786517			0.87860208461066835		0.90055248618784534
		
Mean: 	0.925314009662				0.921086956522				0.9260104549				0.917347187019				0.880699567613			0.878550571668
		
b) Performance of Regularized Logistic Regression: (Optimal value of lambda = 0.8)

		Training Accuracies         Testing Accuracies          Training Precisions         Testing Precisions  		Training Recalls 		Testing Recalls	
		0.9258454106280193			0.9326086956521739        	0.9259493670886076         	0.9324324324324325      	0.8850574712643678      0.8679245283018868        
		0.9265700483091788			0.9260869565217391			0.9292091836734694			0.9							0.883030303030303		0.8888888888888888
		0.9243961352657005			0.9369565217391305			0.9256410256410257			0.9551282051282052			0.8799512492382694		0.8713450292397661
		0.9263285024154589			0.9304347826086956			0.9278215223097113			0.9476439790575916			0.8788067122436296		0.8916256157635468
		0.9318840579710145			0.9195652173913044			0.9319948186528497			0.9297297297297298			0.8904702970297029		0.8775510204081632
		0.9292270531400966			0.9195652173913044			0.9300064808813999			0.9057591623036649			0.8858024691358025		0.9010416666666666
		0.9297101449275362			0.9021739130434783			0.9276649746192893			0.8950617283950617			0.8920073215375229		0.838150289017341
		0.9285024154589372			0.9347826086956522			0.9271907216494846			0.949438202247191			0.8871763255240444		0.8894736842105263
		0.9304347826086956 			0.9239130434782609			0.9316730523627076			0.9005847953216374			0.8896341463414634		0.8953488372093024
		0.9299516908212561			0.9173913043478261			0.9294954721862871			0.9193548387096774			0.8881334981458591		0.8814432989690721

Mean:	0.9282850241545894			0.9243478260869565			0.9286646619064832			0.9235133073325191			0.8860069793490966		0.880279285867516
		

